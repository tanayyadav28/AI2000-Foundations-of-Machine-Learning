# Introduction

Here we worked with Regressors: 
1. Gradient Boosting Regressor.  
2. Linear Regression.  
3. Random Forest Regressor.   
4. AdaBoost Regressor.   
5. K Neighbors Regressor. 
6. Logistic Regressor.

Out of these, the Logistic Regressor was implemented from scratch while the rest were from **sklearn.ensemble, sklearn.linear_model, and sklearn.neighbors**. 

# Logistic Regressor

Implemented my own code for a Logistic Regression Classifier, which is trained using gradient descent and cross-entropy error as the error function.

# Kaggle Taxi-Fare Prediction

This was a completed challenge on Kaggle. Six different regressors were trained and tested on this dataset and the best performing ones were highlighted based 
upon their RMSE score.

# Requirements

numpy == 1.19.2   
sklearn == 0.23.2   
pandas == 1.1.3
